cut -d ' ' -f1 ZZOL_trinity.fa > ZZOL_trinity2.fa
#trim header

rm ZZOL_trinity.fa
#remove original

grep -c "^>" ZZOL_trinity2.fa
#count sequences

awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%100==0){file=sprintf("seq%d.fa",n_seq);} print >> file; n_seq++; next;} { print >> file; }' < ZZOL_trinity2.fa
#chunk data
#each fasta with 100 sequences

rm ZZOL_trinity2.fa
#remove large data


~

Prepare data for InterProScan parallel processing. Trim header. We want to split the single FASTA file into many FASTA files that can be processed in parallel, so we create a folder where each FASTA file only contains 100 sequences. To lower the thread count for decreased parallelism, we can increase the number of sequences per FASTA file.